{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beneficial-celtic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n",
      "Tensorflow Version is 2.4.1\n",
      "Keras Version is 2.4.0\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 16582985004382457586\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1048576000\n",
      "locality {\n",
      "  bus_id: 2\n",
      "  numa_node: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 4340440384154876200\n",
      "physical_device_desc: \"device: 0, name: A100-SXM-80GB, pci bus id: 0000:4c:00.0, compute capability: 8.0\"\n",
      "]\n",
      "Tue Feb 22 15:05:06 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.73.01    Driver Version: 460.73.01    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  A100-SXM-80GB       On   | 00000000:4C:00.0 Off |                    0 |\n",
      "| N/A   30C    P0    67W / 400W |   2399MiB / 81251MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# encoding: utf-8\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "# Install TensorFlow\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten , Convolution2D, MaxPooling2D , Lambda, Conv2D, Activation,Concatenate\n",
    "from tensorflow.keras.layers import ActivityRegularization\n",
    "from tensorflow.keras.optimizers import Adam , SGD , Adagrad\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras import regularizers , initializers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import NumpyArrayIterator\n",
    "\n",
    "\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#   # Restrict TensorFlow to only use the first GPU\n",
    "try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "    gpus[0],\n",
    "    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1000)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "except RuntimeError as e:\n",
    "# Visible devices must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n",
    "# from xgboost import XGBClassifier\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn import metrics\n",
    "\n",
    "# !pip3 install keras-tuner --upgrade\n",
    "# !pip3 install autokeras\n",
    "import kerastuner as kt\n",
    "import autokeras as ak\n",
    "\n",
    "#Plot's Making  Packages\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator, MultipleLocator, AutoMinorLocator\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap, BoundaryNorm\n",
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib import cm\n",
    "from matplotlib import font_manager\n",
    "\n",
    "\n",
    "# Import local libraries\n",
    "import numpy as np\n",
    "import h5py\n",
    "import time\n",
    "import pandas as pd\n",
    "import importlib\n",
    "from scipy import interpolate\n",
    "import os\n",
    "from tqdm import tqdm \n",
    "\n",
    "import logging\n",
    "\n",
    "importlib.reload(logging)\n",
    "logging.basicConfig(level = logging.INFO)\n",
    "\n",
    "os.environ['NUMEXPR_MAX_THREADS'] = '64'\n",
    "os.environ['NUMEXPR_NUM_THREADS'] = '64'\n",
    "\n",
    "print(\"Tensorflow Version is {}\".format(tf.__version__))\n",
    "print(\"Keras Version is {}\".format(tf.keras.__version__))\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "tf.device('/device:XLA_GPU:0')\n",
    "!nvidia-smi\n",
    "\n",
    "%config InlineBackend. figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dietary-handle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model_CNN_herwig_ang_0\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv2D_1 (Conv2D)            (None, 96, 36, 36)        7296      \n",
      "_________________________________________________________________\n",
      "jet_MaxPooling_1 (MaxPooling (None, 48, 18, 36)        0         \n",
      "_________________________________________________________________\n",
      "Conv2D_2 (Conv2D)            (None, 32, 14, 32)        38432     \n",
      "_________________________________________________________________\n",
      "jet_MaxPooling_2 (MaxPooling (None, 32, 7, 16)         0         \n",
      "_________________________________________________________________\n",
      "jet_flatten (Flatten)        (None, 3584)              0         \n",
      "_________________________________________________________________\n",
      "jet_dense_1 (Dense)          (None, 350)               1254750   \n",
      "_________________________________________________________________\n",
      "jet_dense_2 (Dense)          (None, 400)               140400    \n",
      "_________________________________________________________________\n",
      "Dropout (Dropout)            (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 401       \n",
      "=================================================================\n",
      "Total params: 1,441,279\n",
      "Trainable params: 1,441,279\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "filepath = \"./KFold_CNN/\"+str(\"herwig_ang\")+\"_KFold/CNN_\"+str(\"herwig_ang\")+\"_Models_\"+str(int(300))+str(int(500))+\"/\" + str(\"herwig_ang\") + \"_CNN_\"+str(0)+ \".h5\"\n",
    "if os.path.exists(filepath):\n",
    "#                     CNN_Model_A1[model] = load_model(filepath)\n",
    "\n",
    "    model_CNN = load_model(filepath)\n",
    "model_CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "failing-python",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Loading_Data(data_source, datadict, start=0, stop=20000):\n",
    "    x_jet, target = [], []\n",
    "\n",
    "    time.sleep(0.5)\n",
    "    for k in tqdm(range(start,len(data_source))):\n",
    "        x_jet_path = savepath + \"Image_Directory/\"+ data_source[\"JetImage\"].iloc[k]\n",
    "        x_jet_tmp = np.load(x_jet_path)[\"jet_image\"]\n",
    "#         if np.isnan(x_jet_tmp).any() == True:\n",
    "#             continue \n",
    "        x_jet_tmp = np.nan_to_num(x_jet_tmp)\n",
    "\n",
    "        target.append(data_source[\"Y\"].iloc[k])\n",
    "        x_jet_tmp = np.divide((x_jet_tmp - Norm_dict[datadict][0]), (np.sqrt(Norm_dict[datadict][1])+1e-5))#[0].reshape(1,40,40)\n",
    "        x_jet.append(x_jet_tmp)\n",
    "\n",
    "\n",
    "        if k == stop:\n",
    "            break\n",
    "\n",
    "    return np.asarray(x_jet), np.asarray(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "southeast-advancement",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:START===========================================START\n",
      "INFO:root:\n",
      "INFO:root:All Files are loaded!\n",
      "INFO:root:pt min: 300 , pt max: 500\n",
      "INFO:root:\n",
      "INFO:root:H jet : QCD jet = 1 : 1\n",
      "INFO:root:herwig_ang_train, # of H jet: 153728\n",
      "INFO:root:herwig_ang_train, # of QCD jet: 153728\n",
      "INFO:root:Train #     307456     \n",
      "100%|██████████| 307456/307456 [06:24<00:00, 799.71it/s]\n",
      "INFO:root:Test Data: herwig_ang_train\n",
      "INFO:root:pythia_dip CNN models apply on herwig_ang_train is finished!!\n",
      "INFO:root:END===========================================END\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:START===========================================START\n",
      "INFO:root:\n",
      "INFO:root:All Files are loaded!\n",
      "INFO:root:pt min: 300 , pt max: 500\n",
      "INFO:root:\n",
      "INFO:root:H jet : QCD jet = 1 : 1\n",
      "INFO:root:pythia_def_train, # of H jet: 153728\n",
      "INFO:root:pythia_def_train, # of QCD jet: 153728\n",
      "INFO:root:Train #     307456     \n",
      "100%|██████████| 307456/307456 [06:07<00:00, 836.67it/s]\n",
      "INFO:root:Test Data: pythia_def_train\n",
      "INFO:root:pythia_dip CNN models apply on pythia_def_train is finished!!\n",
      "INFO:root:END===========================================END\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:START===========================================START\n",
      "INFO:root:\n",
      "INFO:root:All Files are loaded!\n",
      "INFO:root:pt min: 300 , pt max: 500\n",
      "INFO:root:\n",
      "INFO:root:H jet : QCD jet = 1 : 1\n",
      "INFO:root:pythia_vin_train, # of H jet: 153728\n",
      "INFO:root:pythia_vin_train, # of QCD jet: 153728\n",
      "INFO:root:Train #     307456     \n",
      "100%|██████████| 307456/307456 [06:06<00:00, 839.31it/s]\n",
      "INFO:root:Test Data: pythia_vin_train\n",
      "INFO:root:pythia_dip CNN models apply on pythia_vin_train is finished!!\n",
      "INFO:root:END===========================================END\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:START===========================================START\n",
      "INFO:root:\n",
      "INFO:root:All Files are loaded!\n",
      "INFO:root:pt min: 300 , pt max: 500\n",
      "INFO:root:\n",
      "INFO:root:H jet : QCD jet = 1 : 1\n",
      "INFO:root:pythia_dip_train, # of H jet: 153728\n",
      "INFO:root:pythia_dip_train, # of QCD jet: 153728\n",
      "INFO:root:Train #     307456     \n",
      "100%|██████████| 307456/307456 [06:15<00:00, 819.03it/s]\n",
      "INFO:root:Test Data: pythia_dip_train\n",
      "INFO:root:pythia_dip CNN models apply on pythia_dip_train is finished!!\n",
      "INFO:root:END===========================================END\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18min 1s, sys: 6min 37s, total: 24min 39s\n",
      "Wall time: 29min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "HOMEPATH = \"/dicos_ui_home/alanchung/Universality_Boosetd_Higgs/\"\n",
    "Data_High_Level_Features_path =  HOMEPATH + \"Data_High_Level_Features/\"\n",
    "savepath = HOMEPATH + \"Data_ML/\"\n",
    "\n",
    "\n",
    "\n",
    "data_dict ={\n",
    "            \"herwig_ang\" : [0,0],\n",
    "            \"pythia_def\" : [0,0],\n",
    "            \"pythia_vin\" : [0,0],\n",
    "            \"pythia_dip\" : [0,0],\n",
    "#             \"sherpa_def\" : [0,0],\n",
    "          }  \n",
    "\n",
    "Norm_dict ={\n",
    "            \"herwig_ang\" : [0,0],\n",
    "            \"pythia_def\" : [0,0],\n",
    "            \"pythia_vin\" : [0,0],\n",
    "            \"pythia_dip\" : [0,0],\n",
    "#             \"sherpa_def\" : [0,0],\n",
    "          }  \n",
    "\n",
    "data_train = {\n",
    "            \"herwig_ang_train\" : 0,\n",
    "            \"pythia_def_train\" : 0,\n",
    "            \"pythia_vin_train\" : 0,\n",
    "            \"pythia_dip_train\" : 0,\n",
    "#             \"sherpa_def_train\" : 0\n",
    "            }  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "CNN_Model_A1 = {\n",
    "      \"herwig_ang\" : load_model(\"./KFold_CNN/herwig_ang_KFold/CNN_herwig_ang_Models_300500/herwig_ang_CNN_0.h5\"),\n",
    "      \"pythia_def\" : load_model(\"./KFold_CNN/pythia_def_KFold/CNN_pythia_def_Models_300500/pythia_def_CNN_0.h5\"),\n",
    "      \"pythia_vin\" : load_model(\"./KFold_CNN/pythia_vin_KFold/CNN_pythia_vin_Models_300500/pythia_vin_CNN_0.h5\"),\n",
    "      \"pythia_dip\" : load_model(\"./KFold_CNN/pythia_dip_KFold/CNN_pythia_dip_Models_300500/pythia_dip_CNN_0.h5\"),\n",
    "    }\n",
    "\n",
    "       \n",
    "    \n",
    "pd_datafram_save = {\n",
    "            \"herwig_ang_train\" : pd.DataFrame(),\n",
    "            \"pythia_def_train\" : pd.DataFrame(),\n",
    "            \"pythia_vin_train\" : pd.DataFrame(),\n",
    "            \"pythia_dip_train\" : pd.DataFrame(),\n",
    "            }  \n",
    "\n",
    "\n",
    "for j, element in enumerate(data_dict):\n",
    "    data_dict[element][0] = pd.read_csv(savepath + str(element) + \"_H_dict.csv\")\n",
    "    data_dict[element][1] = pd.read_csv(savepath + str(element) + \"_QCD_dict.csv\")\n",
    "#         logging.info(len(data_dict[element][0]),len(data_dict[element][1]))\n",
    "\n",
    "for j, element in enumerate(Norm_dict):\n",
    "    average_H = np.load(savepath + \"average\" + \"_\" + str(element) + \"_H.npy\")\n",
    "    variance_H = np.load(savepath + \"variance\" + \"_\" + str(element) + \"_H.npy\")\n",
    "    average_QCD = np.load(savepath + \"average\" + \"_\" + str(element) + \"_QCD.npy\")\n",
    "    variance_QCD = np.load(savepath + \"variance\" + \"_\" + str(element) + \"_QCD.npy\")\n",
    "    length_H = len(data_dict[element][0])\n",
    "    length_QCD = len(data_dict[element][1])\n",
    "\n",
    "    Norm_dict[element][0] = (average_H*length_H + average_QCD*length_QCD)/(length_H+length_QCD)\n",
    "    Norm_dict[element][1] =  variance_H + variance_QCD\n",
    "\n",
    "for j, (traindata, datadict) in enumerate(zip(data_train, data_dict)):\n",
    "\n",
    "    \n",
    "    train_data_path = HOMEPATH + \"Notebook/KFold_CNN/\" + str(traindata) + \".csv\"\n",
    "    if os.path.exists(train_data_path):\n",
    "        tmp = pd.read_csv(train_data_path)\n",
    "    else:\n",
    "        raise ValueError(\"Pleas check training data path !!\")\n",
    "\n",
    "    tmp = tmp[(tmp[\"PTJ_0\"] >= 300)  & (tmp[\"PTJ_0\"] < 500)]\n",
    "    tmp = tmp[(tmp[\"MJ_0\"] >= 110)  & (tmp[\"MJ_0\"] < 160)]\n",
    "    data_train[traindata] = tmp#[:30000]\n",
    "\n",
    "    H_tmp = data_train[traindata][data_train[traindata][\"target\"] == 1]\n",
    "    QCD_tmp = data_train[traindata][data_train[traindata][\"target\"] == 0]\n",
    "\n",
    "    H_dict = data_dict[datadict][0].iloc[H_tmp[\"index\"].values]\n",
    "    QCD_dict = data_dict[datadict][1].iloc[QCD_tmp[\"index\"].values]\n",
    "\n",
    "    data_train[traindata] = pd.concat([H_dict, QCD_dict], ignore_index=True, axis=0,join='inner')\n",
    "    data_train[traindata] = data_train[traindata]\n",
    "\n",
    "\n",
    "    logging.info(\"START===========================================START\")\n",
    "    logging.info(\"\\r\") \n",
    "    logging.info(\"All Files are loaded!\")\n",
    "    logging.info(\"pt min: {} , pt max: {}\".format(300, 500))\n",
    "    logging.info(\"\\r\")\n",
    "    logging.info(\"H jet : QCD jet = 1 : 1\")\n",
    "    logging.info(\"{}, # of H jet: {}\".format(traindata, len(H_dict)))\n",
    "    logging.info(\"{}, # of QCD jet: {}\".format(traindata, len(QCD_dict)))\n",
    "    train = len(data_train[traindata])\n",
    "    logging.info(\"{:^8}{:^15}\".format(\"Train #\",train))\n",
    "\n",
    "\n",
    "    x_jet, target = Loading_Data(data_train[traindata], datadict, start=0, stop= len(data_train[traindata]))\n",
    "\n",
    "    logging.info(\"Test Data: {}\".format(traindata))\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    for i, model in enumerate(CNN_Model_A1): \n",
    "        \n",
    "        prediction = CNN_Model_A1[model].predict(np.asarray(x_jet))\n",
    "        pd_datafram_save[traindata][model+\"_cnn_pre\"] = prediction.reshape(len(prediction),)\n",
    "\n",
    "    logging.info(\"{} CNN models apply on {} is finished!!\".format(model,traindata))\n",
    "    logging.info(\"END===========================================END\")\n",
    "    logging.info(\"\\n\")\n",
    "\n",
    "\n",
    "logging.info(\"\\n\")\n",
    "logging.info(\"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "specific-applicant",
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in pd_datafram_save:\n",
    "    pd_datafram_save[element].to_csv(\"./\"+element+\"_CNN.csv\", index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-mixer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
