{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Numpy Version: 1.19.5\n",
      "INFO:root:Pnadas Version: 1.1.5\n",
      "INFO:root:Sklearn Version: 0.24.1\n"
     ]
    }
   ],
   "source": [
    "# Numerical Packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Common packages\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import re \n",
    "import glob\n",
    " \n",
    "#Plot's Making  Packages\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "#System Packages\n",
    "import importlib\n",
    "import time\n",
    "import os\n",
    "from os.path import isdir, isfile, join\n",
    "import logging\n",
    "\n",
    "importlib.reload(logging)\n",
    "logging.basicConfig(level = logging.INFO)\n",
    "\n",
    "\n",
    "# Learning packages\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "logging.info(\"Numpy Version: {}\".format(np.__version__))\n",
    "logging.info(\"Pnadas Version: {}\".format(pd.__version__))\n",
    "logging.info(\"Sklearn Version: {}\".format(sklearn.__version__))\n",
    "\n",
    "%config InlineBackend. figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine High-Level-Feature Data from CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]INFO:root:Combing Data for herwig_ang_H\n",
      "INFO:root:\u001b[3;43m Total File Length: 791586 \u001b[0;m\n",
      "INFO:root:\n",
      "1it [00:24, 24.78s/it]INFO:root:Combing Data for herwig_ang_QCD\n",
      "INFO:root:\u001b[3;43m Total File Length: 1389852 \u001b[0;m\n",
      "INFO:root:\n",
      "2it [01:23, 34.97s/it]INFO:root:Combing Data for pythia_def_H\n",
      "INFO:root:\u001b[3;43m Total File Length: 802911 \u001b[0;m\n",
      "INFO:root:\n",
      "3it [01:48, 32.06s/it]INFO:root:Combing Data for pythia_def_QCD\n",
      "INFO:root:\u001b[3;43m Total File Length: 1633160 \u001b[0;m\n",
      "INFO:root:\n",
      "4it [02:56, 42.80s/it]INFO:root:Combing Data for pythia_vin_H\n",
      "INFO:root:\u001b[3;43m Total File Length: 796330 \u001b[0;m\n",
      "INFO:root:\n",
      "5it [03:22, 37.65s/it]INFO:root:Combing Data for pythia_vin_QCD\n",
      "INFO:root:\u001b[3;43m Total File Length: 1412403 \u001b[0;m\n",
      "INFO:root:\n",
      "6it [04:28, 46.33s/it]INFO:root:Combing Data for pythia_dip_H\n",
      "INFO:root:\u001b[3;43m Total File Length: 802791 \u001b[0;m\n",
      "INFO:root:\n",
      "7it [04:54, 40.08s/it]INFO:root:Combing Data for pythia_dip_QCD\n",
      "INFO:root:\u001b[3;43m Total File Length: 2089101 \u001b[0;m\n",
      "INFO:root:\n",
      "8it [06:43, 50.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: Index(['GEN', 'SHO', 'PRO', 'MJ_0', 'PTJ_0', 'eta_0', 'phi_0', 't21_0',\n",
      "       'D21_0', 'D22_0', 'C21_0', 'C22_0', 'MJ', 'PTJ', 'eta', 'phi', 't21',\n",
      "       'D21', 'D22', 'C21', 'C22', 'weight', 'eventindex', 'WEIGHT', 'index'],\n",
      "      dtype='object')\n",
      "CPU times: user 5min 42s, sys: 1min, total: 6min 42s\n",
      "Wall time: 6min 43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "def High_Level_Features(csv_file=[]):\n",
    "    \n",
    "    if len(csv_file) < 1:\n",
    "        raise Inputerror(\"Please check high-level features files!!\")\n",
    "        \n",
    "    \n",
    "    high_level_feature = pd.read_csv(csv_file[0])\n",
    "#     high_level_feature = high_level_feature[(high_level_feature[\"PTJ_0\"] > 300 ) & (high_level_feature[\"PTJ_0\"] <= 500 )]\n",
    "#     high_level_feature = high_level_feature[(high_level_feature[\"PTJ_0\"] > 300 )]\n",
    "#     logging.info(str(csv_file[0]))\n",
    "#     logging.info(\"File Length: {}\".format(len(high_level_feature)))\n",
    "#     logging.info(\"Higgs jet Pt min: {:.3f},  Higgs jet Pt max: {:.3f}\".format(high_level_feature[\"PTJ_0\"].min(),high_level_feature[\"PTJ_0\"].max()))\n",
    "#     logging.info(\"\\r\")\n",
    "    \n",
    "    for i, file in enumerate(csv_file):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        else:\n",
    "#             logging.info(str(file))\n",
    "            \n",
    "            if \"250_500\" in str(file):\n",
    "\n",
    "                dataframe = pd.read_csv(file)\n",
    "#                 dataframe = dataframe[(dataframe[\"PTJ_0\"] > 300) & (dataframe[\"PTJ_0\"] <= 500)]\n",
    "            \n",
    "            elif \"450_700\" in str(file):\n",
    "\n",
    "                dataframe = pd.read_csv(file)\n",
    "#                 dataframe = dataframe[(dataframe[\"PTJ_0\"] > 300) & (dataframe[\"PTJ_0\"] <= 500)]\n",
    "                \n",
    "#             elif \"650_900\" in str(file):\n",
    "\n",
    "#                 dataframe = pd.read_csv(file)\n",
    "#                 dataframe = dataframe[(dataframe[\"PTJ_0\"] > 700) & (dataframe[\"PTJ_0\"] <= 900)]\n",
    "            \n",
    "#             elif \"850_1100\" in str(file):\n",
    "\n",
    "#                 dataframe = pd.read_csv(file)\n",
    "#                 dataframe = dataframe[(dataframe[\"PTJ_0\"] > 900) & (dataframe[\"PTJ_0\"] <= 1100)]\n",
    "            \n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "#             dataframe = dataframe[(dataframe[\"PTJ_0\"] > 300 )]\n",
    "            high_level_feature = pd.concat([high_level_feature, dataframe], ignore_index=True, axis=0,join='inner')\n",
    "            high_level_feature[\"WEIGHT\"] = high_level_feature[\"weight\"]/(len(csv_file)//4)\n",
    "        \n",
    "        \n",
    "#         logging.info(\"File Length: {}\".format(len(dataframe)))\n",
    "#         logging.info(\"Higgs jet Pt min: {:.3f},  Higgs jet Pt max: {:.3f}\".format(dataframe[\"PTJ_0\"].min(),dataframe[\"PTJ_0\"].max()))\n",
    "#         logging.info(\"\\r\")\n",
    "    \n",
    "    logging.info( \"\\033[3;43m Total File Length: {} \\033[0;m\".format(len(high_level_feature)))\n",
    "    logging.info(\"\\r\")\n",
    "    \n",
    "    return high_level_feature\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Local and Data Path @ASGC\n",
    "\"\"\"\n",
    "path = \"/dicos_ui_home/alanchung/Universality_Boosetd_Higgs/Data_ML/Data_High_Level_Features\"\n",
    "    \n",
    "    \n",
    "process = {\n",
    "            \"herwig_ang_H\" : 0,\n",
    "            \"herwig_ang_QCD\" : 0,\n",
    "            \"pythia_def_H\" : 0,\n",
    "            \"pythia_def_QCD\" : 0,\n",
    "            \"pythia_vin_H\" : 0,\n",
    "            \"pythia_vin_QCD\" : 0,\n",
    "            \"pythia_dip_H\" : 0,\n",
    "            \"pythia_dip_QCD\" : 0 ,\n",
    "#                 \"sherpa_def_H\" : 0,\n",
    "#                 \"sherpa_def_QCD\" : 0\n",
    "              }  \n",
    "\n",
    "try:\n",
    "    \n",
    "    for index, element in tqdm(enumerate(process)):\n",
    "        \n",
    "#         if index%2 == 0:\n",
    "            \n",
    "        process[element] = pd.read_csv(path + \"/\" + str(element) + \".csv\")\n",
    "\n",
    "        logging.info(\"{}'s event number: {}\".format(element,len(process[element])))\n",
    "            \n",
    "#         if index%2 == 1:\n",
    "            \n",
    "#             process[element] = pd.read_csv(path + \"/\" + str(element) + \".csv\")\n",
    "            \n",
    "#             process[element] = pd.concat([process[element] for i in range(10)],ignore_index=True,axis=0,join='inner')\n",
    "#             process[element].drop(columns='index')\n",
    "#             process[element][\"index\"]= np.linspace(0,len(process[element])-1,len(process[element]),dtype=\"int\")\n",
    "#             process[element].to_csv(path + \"/\" + str(element) + \".csv\",index = 0)\n",
    "            \n",
    "#             print(\"{}'s event number: {}\".format(element,len(process[element])))\n",
    "        \n",
    "        \n",
    "        \n",
    "except:\n",
    "\n",
    "    for index, element in tqdm(enumerate(process)):\n",
    "        logging.info(\"Combing Data for {}\".format(element))\n",
    "\n",
    "        csv_files = sorted(glob.glob(path+\"/\"+str(element)+\"_*.csv\"))\n",
    "        process[element] = High_Level_Features(csv_files)\n",
    "        process[element][\"index\"]= np.linspace(0,len(process[element])-1,len(process[element]),dtype=\"int\")\n",
    "        process[element].to_csv(path + \"/\" + str(element) + \".csv\",index = 0)\n",
    "\n",
    "        \n",
    "        \n",
    "#         if index%2 == 1:\n",
    "            \n",
    "#             process[element] = pd.read_csv(path + \"/\" + str(element) + \".csv\")\n",
    "            \n",
    "#             process[element] = pd.concat([process[element] for i in range(20)],ignore_index=True,axis=0,join='inner')\n",
    "#             process[element].drop(columns='index')\n",
    "#             process[element][\"index\"]= np.linspace(0,len(process[element])-1,len(process[element]),dtype=\"int\")\n",
    "#             process[element].to_csv(path + \"/\" + str(element) + \".csv\",index = 0)\n",
    "            \n",
    "            \n",
    "#             print(\"{}'s event number: {}\".format(element,len(process[element])))\n",
    "        \n",
    "        \n",
    "    \n",
    "feature = process[\"pythia_def_H\"].columns\n",
    "logging.info(\"Features: {}\".format(feature))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Image Lists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]INFO:root:\n",
      "\n",
      "INFO:root:List path: /dicos_ui_home/alanchung/Universality_Boosetd_Higgs/Data_ML/herwig_ang_H_dict.csv\n",
      "INFO:root:herwig_ang_H's event number: 791586\n",
      "1it [00:02,  2.65s/it]INFO:root:\n",
      "\n",
      "INFO:root:List path: /dicos_ui_home/alanchung/Universality_Boosetd_Higgs/Data_ML/herwig_ang_QCD_dict.csv\n",
      "INFO:root:herwig_ang_QCD's event number: 1389852\n",
      "2it [00:07,  3.21s/it]INFO:root:\n",
      "\n",
      "INFO:root:List path: /dicos_ui_home/alanchung/Universality_Boosetd_Higgs/Data_ML/pythia_def_H_dict.csv\n",
      "INFO:root:pythia_def_H's event number: 802911\n",
      "3it [00:09,  3.03s/it]INFO:root:\n",
      "\n",
      "INFO:root:List path: /dicos_ui_home/alanchung/Universality_Boosetd_Higgs/Data_ML/pythia_def_QCD_dict.csv\n",
      "INFO:root:pythia_def_QCD's event number: 1633160\n",
      "4it [00:15,  3.72s/it]INFO:root:\n",
      "\n",
      "INFO:root:List path: /dicos_ui_home/alanchung/Universality_Boosetd_Higgs/Data_ML/pythia_vin_H_dict.csv\n",
      "INFO:root:pythia_vin_H's event number: 796330\n",
      "5it [00:17,  3.38s/it]INFO:root:\n",
      "\n",
      "INFO:root:List path: /dicos_ui_home/alanchung/Universality_Boosetd_Higgs/Data_ML/pythia_vin_QCD_dict.csv\n",
      "INFO:root:pythia_vin_QCD's event number: 1412403\n",
      "6it [00:22,  3.74s/it]INFO:root:\n",
      "\n",
      "INFO:root:List path: /dicos_ui_home/alanchung/Universality_Boosetd_Higgs/Data_ML/pythia_dip_H_dict.csv\n",
      "INFO:root:pythia_dip_H's event number: 802791\n",
      "7it [00:24,  3.41s/it]INFO:root:\n",
      "\n",
      "INFO:root:List path: /dicos_ui_home/alanchung/Universality_Boosetd_Higgs/Data_ML/pythia_dip_QCD_dict.csv\n",
      "INFO:root:pythia_dip_QCD's event number: 2089101\n",
      "8it [00:31,  3.98s/it]\n"
     ]
    }
   ],
   "source": [
    "HOMEPATH = \"/dicos_ui_home/alanchung/Universality_Boosetd_Higgs/\"\n",
    "JetImagePath =  HOMEPATH + \"Data_ML/\" +\"Image_Directory/\"\n",
    "savepath = HOMEPATH + \"Data_ML/\"\n",
    "\n",
    "process = {\n",
    "            \"herwig_ang_H\" : 0,\n",
    "            \"herwig_ang_QCD\" : 0,\n",
    "            \"pythia_def_H\" : 0,\n",
    "            \"pythia_def_QCD\" : 0,\n",
    "            \"pythia_vin_H\" : 0,\n",
    "            \"pythia_vin_QCD\" : 0,\n",
    "            \"pythia_dip_H\" : 0,\n",
    "            \"pythia_dip_QCD\" : 0 ,\n",
    "#             \"sherpa_def_H\" : 0,\n",
    "#             \"sherpa_def_QCD\" : 0\n",
    "              }  \n",
    "\n",
    "    \n",
    "try:\n",
    "    \n",
    "    for element in tqdm(process):\n",
    "        total_data = pd.read_csv(savepath + str(element) + \"_dict.csv\")\n",
    "    \n",
    "    \n",
    "        logging.info(\"List path: {}\".format(savepath + str(element) + \"_dict.csv\"))\n",
    "        logging.info(\"{}'s event number: {}\".format(element,len(total_data)))\n",
    "        \n",
    "\n",
    "except:\n",
    "    \n",
    "    try: \n",
    "        folder_list_tmp = os.listdir(JetImagePath)\n",
    "        \n",
    "        for label, element in tqdm(enumerate(process)):\n",
    "            img_length = 0\n",
    "            path_jet_image = []\n",
    "            folder_list = []\n",
    "\n",
    "            for i, folder in enumerate(folder_list_tmp):\n",
    "                    if isdir( join(JetImagePath, folder)):\n",
    "                       \n",
    "                        if folder[:12] == str(element):\n",
    "                            folder_list.append([folder,int(folder[17:])])\n",
    "\n",
    "\n",
    "                        if folder[:14] == str(element):\n",
    "                            folder_list.append([folder,int(folder[19:])])\n",
    "\n",
    "            folder_list = sorted(folder_list, key = lambda s: s[1])\n",
    "#             logging.info(\"folder_list: {}\".format(folder_list))\n",
    "            for i, folder in enumerate(folder_list):\n",
    "                \n",
    "                if isdir( join(JetImagePath, folder[0])):\n",
    "\n",
    "                    if label%2 == 0:\n",
    "                        if folder[0][:12] == str(element):\n",
    "                            images_folder_tmp = os.listdir(join(JetImagePath, folder[0]))\n",
    "\n",
    "                            images_folder = sorted(images_folder_tmp, key = lambda s: int(s[6:len(s)-4]))\n",
    "\n",
    "                            for image in images_folder:\n",
    "                                path_jet_image.append(folder[0] + \"/\" + image)\n",
    "\n",
    "                            img_length += len(images_folder)\n",
    "\n",
    "                    if label%2 == 1:\n",
    "                        if folder[0][:14] == str(element):\n",
    "                            images_folder_tmp = os.listdir(join(JetImagePath, folder[0]))\n",
    "                            images_folder = sorted(images_folder_tmp, key = lambda s: int(s[6:len(s)-4]))\n",
    "\n",
    "                            for image in images_folder:\n",
    "                                path_jet_image.append(folder[0] + \"/\" + image)\n",
    "\n",
    "                            img_length += len(images_folder)\n",
    "                         \n",
    "                    \n",
    "            if label%2 == 0:\n",
    "                Ydata = np.full(img_length, 1) # Higgs Jet\n",
    "            if label%2 == 1:\n",
    "                Ydata = np.full(img_length, 0) # QCD Jet\n",
    "\n",
    "            dataframe = pd.DataFrame()\n",
    "            dataframe[\"JetImage\"] = path_jet_image\n",
    "            dataframe[\"Y\"] = np.array(Ydata,dtype=\"int\")\n",
    "            dataframe.to_csv(savepath + str(element) + \"_dict.csv\",index = 0)\n",
    "            \n",
    "            logging.info(\"\\n\")\n",
    "            logging.info(\"List path: {}\".format(savepath  + str(element) + \"_dict.csv\"))\n",
    "            logging.info(\"{}'s event number: {}\".format(element,len(dataframe)))\n",
    "    except:\n",
    "        \n",
    "        logging.info(\"error\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data into Training, Validation and Test dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov 16 15:03:17 2021\n",
      "herwig_ang_H 791586\n",
      "herwig_ang_QCD 1389852\n",
      "pythia_def_H 802911\n",
      "pythia_def_QCD 1633160\n",
      "pythia_vin_H 796330\n",
      "pythia_vin_QCD 1412403\n",
      "pythia_dip_H 802791\n",
      "pythia_dip_QCD 2089101\n",
      "herwig_ang_H Preselection Efficiency: 0.403\n",
      "herwig_ang_QCD Preselection Efficiency: 0.124\n",
      "pythia_def_H Preselection Efficiency: 0.374\n",
      "pythia_def_QCD Preselection Efficiency: 0.108\n",
      "pythia_vin_H Preselection Efficiency: 0.382\n",
      "pythia_vin_QCD Preselection Efficiency: 0.109\n",
      "pythia_dip_H Preselection Efficiency: 0.386\n",
      "pythia_dip_QCD Preselection Efficiency: 0.115\n",
      "All Files are loaded!\n",
      "        Herwig Angular Pythia Default  Pythia Vincia  Pythia Dipole \n",
      "  H #       319171         300677         304268         309980     \n",
      " QCD #      172667         176937         153728         239380     \n",
      "\u001b[3;33mTime Cost : 0.4261 min\u001b[0;m\n",
      "\n",
      "All Files are shuffled!\n",
      "\u001b[3;33mTime Cost : 0.4306 min\u001b[0;m\n",
      "\n",
      "Prepare Training Files\n",
      "\u001b[3;33mTime Cost : 0.4306 min\u001b[0;m\n",
      "\n",
      "Prepare Target Labels\n",
      "\u001b[3;33mTime Cost : 0.4325 min\u001b[0;m\n",
      "\n",
      "Save training, test and validation datasets\n",
      "\u001b[3;33mTime Cost : 0.4326 min\u001b[0;m\n",
      "\n",
      "All Files are saved!\n",
      "\u001b[3;33mTime Cost : 1.0239 min\u001b[0;m\n",
      "\n",
      "H jet : QCD jet = 1 : 1\n",
      "\n",
      "        Pythia Default \n",
      "Train #     307456     \n",
      " Test #        0       \n",
      " Val. #        0       \n",
      "        Herwig Angular Pythia Default  Pythia Vincia  Pythia Dipole \n",
      "Train #     307456         307456         307456         307456     \n",
      " Test #        0              0              0              0       \n",
      " Val. #        0              0              0              0       \n"
     ]
    }
   ],
   "source": [
    "HOMEPATH = \"/dicos_ui_home/alanchung/Universality_Boosetd_Higgs/\"\n",
    "Data_High_Level_Features_path =  HOMEPATH + \"Data_ML/\" +\"Data_High_Level_Features/\"\n",
    " \n",
    "total_list = ['GEN', 'SHO', 'PRO', 'MJ_0', 'PTJ_0', 'eta_0', 'phi_0', 't21_0',\n",
    "       'D21_0', 'D22_0', 'C21_0', 'C22_0', 'MJ', 'PTJ', 'eta', 'phi', 't21',\n",
    "       'D21', 'D22', 'C21', 'C22', 'weight', 'eventindex', 'WEIGHT', 'index']\n",
    "\n",
    "# if preprocess = \"trimmed\":\n",
    "\n",
    "#     features =  [\"MJ\",\"PTJ\",\"t12\",\"D21\",\"D22\",\"C21\",\"C22\"]\n",
    "    \n",
    "# elif if preprocess = \"untrimmed\":\n",
    "    \n",
    "#      features =  [\"MJ_0\",\"PTJ_0\",\"t12_0\",\"D21_0\",\"D22_0\",\"C21_0\",\"C22_0\"]\n",
    "\n",
    "if os.path.exists(HOMEPATH + \"Data_ML/BDT\") == 0:\n",
    "    os.mkdir(HOMEPATH + \"Data_ML/BDT/\")\n",
    "    datapath = HOMEPATH + \"Data_ML/Data_High_Level_Features/\"\n",
    "#     savepath = HOMEPATH + \"Data_ML/BDT/\"\n",
    "    savepath = HOMEPATH +  \"Notebook/KFold/\"\n",
    "    \n",
    "else: \n",
    "    datapath = HOMEPATH + \"Data_ML/Data_High_Level_Features/\"\n",
    "#     savepath = HOMEPATH + \"Data_ML/BDT/\"\n",
    "    savepath = HOMEPATH +  \"Notebook/KFold/\"\n",
    "\n",
    "\n",
    "\n",
    "#######################################################################################\n",
    "print(time.strftime(\"%a %b %d %H:%M:%S %Y\", time.localtime()))\n",
    "ticks_1 = time.time()    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    \n",
    "    data_train = {\n",
    "#             \"herwig_ang_train\" : 0,\n",
    "            \"pythia_def_train\" : 0,\n",
    "#             \"pythia_vin_train\" : 0,\n",
    "#             \"pythia_dip_train\" : 0,\n",
    "#             \"sherpa_def_train\" : 0\n",
    "            }  \n",
    "    \n",
    "    data_test = {\n",
    "#             \"herwig_ang_test\" : 0,\n",
    "            \"pythia_def_test\" : 0,\n",
    "#             \"pythia_vin_test\" : 0,\n",
    "#             \"pythia_dip_test\" : 0,\n",
    "#             \"sherpa_def_test\" : 0\n",
    "            }  \n",
    "    \n",
    "    data_val = {\n",
    "#             \"herwig_ang_val\" : 0,\n",
    "            \"pythia_def_val\" : 0,\n",
    "#             \"pythia_vin_val\" : 0,\n",
    "#             \"pythia_dip_val\" : 0,\n",
    "#             \"sherpa_def_val\" : 0\n",
    "            }  \n",
    "    \n",
    "    for i, element in enumerate(data_train):\n",
    "        data_train[element] = pd.read_csv(savepath + str(element) + \".csv\")\n",
    "        \n",
    "    for i, element in enumerate(data_test):\n",
    "        data_test[element] = pd.read_csv(savepath + str(element) + \".csv\")\n",
    "        \n",
    "    for i, element in enumerate(data_val):\n",
    "        data_val[element] = pd.read_csv(savepath + str(element) + \".csv\")\n",
    "\n",
    "    print(\"All Files are loaded!\")\n",
    "\n",
    "    ticks_2 = time.time()\n",
    "    totaltime =  ticks_2 - ticks_1\n",
    "    print(\"\\033[3;33mTime Cost : {:.4f} min\\033[0;m\".format(totaltime/60.))\n",
    "    #######################################################################################\n",
    "\n",
    "    print(\"H jet : QCD jet = 1 : 1\")\n",
    "    print(\"\\r\")\n",
    "#     print(\"{:^8}{:^15}\".format(\"\",\"Pythia Default\"))\n",
    "#     print(\"{:^8}{:^15}\".format(\"Train #\",len(data_train[\"pythia_def_train\"])))\n",
    "#     print(\"{:^8}{:^15}\".format(\"Test #\",len(data_test[\"pythia_def_test\"])))\n",
    "#     print(\"{:^8}{:^15}\".format(\"Val. #\",len(data_val[\"pythia_def_val\"])))\n",
    "\n",
    "    train = [ len(data_train[element]) for j, element in enumerate(data_train)]\n",
    "    test = [len(data_test[element]) for j, element in enumerate(data_test)]\n",
    "    val = [len(data_val[element]) for j, element in enumerate(data_val)]\n",
    "    \n",
    "    print(\"{:^8}{:^15}{:^15}{:^15}\".format(\"\",\"Herwig Angular\",\"Pythia Vincia\",\"Pythia Dipole\"))\n",
    "    print(\"{:^8}{:^15}{:^15}{:^15}\".format(\"Train #\",train[0],train[1],train[2]))\n",
    "    print(\"{:^8}{:^15}{:^15}{:^15}\".format(\"Test #\",test[0],test[1],test[2]))\n",
    "    print(\"{:^8}{:^15}{:^15}{:^15}\".format(\"Val. #\",val[0],val[1],val[2]))\n",
    "    \n",
    "    \n",
    "\n",
    "except:\n",
    "\n",
    "    process = {\n",
    "            \"herwig_ang_H\" : 0,\n",
    "            \"herwig_ang_QCD\" : 0,\n",
    "            \"pythia_def_H\" : 0,\n",
    "            \"pythia_def_QCD\" : 0,\n",
    "            \"pythia_vin_H\" : 0,\n",
    "            \"pythia_vin_QCD\" : 0,\n",
    "            \"pythia_dip_H\" : 0,\n",
    "            \"pythia_dip_QCD\" : 0 ,\n",
    "#                 \"sherpa_def_H\" : 0,\n",
    "#                 \"sherpa_def_QCD\" : 0\n",
    "              }  \n",
    "    \n",
    "    \n",
    "    for i, element in enumerate(process):\n",
    "        process[element] = pd.read_csv(datapath + str(element) + \".csv\")\n",
    "        \n",
    "\n",
    "    for j, element in enumerate(process):\n",
    "        print(element, len(process[element]))\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    Mass Cut and PT cut\n",
    "    \"\"\"\n",
    "    #######################\n",
    "    for j , element in enumerate(process):\n",
    "        tmp = process[element]\n",
    "        \n",
    "#         \"\"\"\n",
    "#         Leading Jet Cuts\n",
    "#         \"\"\"\n",
    "#         tmp = tmp[(tmp[\"MJ1_0\"] > 50) ]\n",
    "#         tmp = tmp[(tmp[\"PTJ1_0\"] > 450)]\n",
    "#         tmp = tmp[(abs(tmp[\"eta1_0\"]) < 2)]\n",
    "        \n",
    "#         \"\"\"\n",
    "#         Leading Jet Cuts with Higgs Window\n",
    "#         \"\"\"\n",
    "#         tmp = tmp[(tmp[\"MJ_0\"] > 110) ]\n",
    "#         tmp = tmp[(tmp[\"MJ_0\"] < 160) ]\n",
    "        \n",
    "\n",
    "#         \"\"\"\n",
    "#         SubLeading Jet Cuts with Higgs Window\n",
    "#         \"\"\"\n",
    "#         tmp = tmp[(tmp[\"MJ2_0\"] > 110) ]\n",
    "#         tmp = tmp[(tmp[\"MJ2_0\"] < 160) ]\n",
    "        \n",
    "#         \"\"\"\n",
    "#         Full Cuts\n",
    "#         \"\"\"\n",
    "#         tmp = tmp[(tmp[\"MJ1_0\"] > 50) & (tmp[\"MJ2_0\"] > 50)]\n",
    "#         tmp = tmp[(tmp[\"PTJ1_0\"] > 450) & (tmp[\"PTJ2_0\"] > 250)]\n",
    "#         tmp = tmp[(abs(tmp[\"eta1_0\"]) < 2) & (abs(tmp[\"eta2_0\"]) < 2)]\n",
    "#         tmp = tmp[(abs(tmp[\"delta_eta_0\"]) < 1.3)]\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        Combine Leading and Subleading Jet\n",
    "        \"\"\"\n",
    "        tmp = tmp[(tmp[\"PTJ_0\"] > 300) ]\n",
    "        tmp = tmp[(tmp[\"PTJ_0\"] < 500) ]\n",
    "        tmp = tmp[(tmp[\"MJ_0\"] > 110) ]\n",
    "        tmp = tmp[(tmp[\"MJ_0\"] < 160) ]\n",
    "\n",
    "        \n",
    "        print(\"{} Preselection Efficiency: {:.3f}\".format(element,len(tmp)/len(process[element])))\n",
    "        process[element] = tmp\n",
    "    #######################\n",
    "    \n",
    "    print(\"All Files are loaded!\")\n",
    "    \n",
    "    H_length = [ len(process[element]) for j, element in enumerate(process) if j%2 == 0]\n",
    "    QCD_length = [len(process[element]) for j, element in enumerate(process) if j%2 == 1]\n",
    "#     print(H_length)\n",
    "#     print(QCD_length)\n",
    "#     print(\"{:^8}{:^15}{:^15}{:^15}{:^15}{:^15}\".format(\"\",\"Herwig Angular\",\"Pythia Default\",\"Pythia Vincia\",\"Pythia Dipole\",\"Sherpa Default\"))\n",
    "#     print(\"{:^8}{:^15}{:^15}{:^15}{:^15}{:^15}\".format(\"H #\",H_length[0],H_length[1],H_length[2],H_length[3],H_length[4]))\n",
    "#     print(\"{:^8}{:^15}{:^15}{:^15}{:^15}{:^15}\".format(\"QCD #\",len(herwig_ang_QCD),len(pythia_def_QCD),len(pythia_vin_QCD),len(pythia_dip_QCD),len(sherpa_def_QCD)))\n",
    "    \n",
    "    print(\"{:^8}{:^15}{:^15}{:^15}{:^15}\".format(\"\",\"Herwig Angular\",\"Pythia Default\",\"Pythia Vincia\",\"Pythia Dipole\"))\n",
    "    print(\"{:^8}{:^15}{:^15}{:^15}{:^15}\".format(\"H #\",H_length[0],H_length[1],H_length[2],H_length[3]))\n",
    "    print(\"{:^8}{:^15}{:^15}{:^15}{:^15}\".format(\"QCD #\",QCD_length[0],QCD_length[1],QCD_length[2],QCD_length[3]))\n",
    "\n",
    "#     print(\"{:^8}{:^15}{:^15}{:^15}\".format(\"\",\"Herwig Angular\",\"Pythia Vincia\",\"Pythia Dipole\"))\n",
    "#     print(\"{:^8}{:^15}{:^15}{:^15}\".format(\"H #\",H_length[0],H_length[1],H_length[2]))\n",
    "#     print(\"{:^8}{:^15}{:^15}{:^15}\".format(\"QCD #\",QCD_length[0],QCD_length[1],QCD_length[2]))\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "    ticks_2 = time.time()\n",
    "    totaltime =  ticks_2 - ticks_1\n",
    "    print(\"\\033[3;33mTime Cost : {:.4f} min\\033[0;m\".format(totaltime/60.))\n",
    "    print(\"\\r\")\n",
    "    \n",
    "\n",
    "    for j , element in enumerate(process):\n",
    "        process[element] = shuffle(process[element])\n",
    "\n",
    "    print(\"All Files are shuffled!\")\n",
    "    ticks_2 = time.time()\n",
    "    totaltime =  ticks_2 - ticks_1\n",
    "    print(\"\\033[3;33mTime Cost : {:.4f} min\\033[0;m\".format(totaltime/60.))\n",
    "    print(\"\\r\")\n",
    "    \n",
    "\n",
    "    print(\"Prepare Training Files\")\n",
    "    ticks_2 = time.time()\n",
    "    totaltime =  ticks_2 - ticks_1\n",
    "    print(\"\\033[3;33mTime Cost : {:.4f} min\\033[0;m\".format(totaltime/60.))\n",
    "    print(\"\\r\")\n",
    "    \n",
    "    length = np.min([ len(process[element]) for element in process])\n",
    "    \n",
    "    data_train = {\n",
    "            \"herwig_ang_train\" : 0,\n",
    "            \"pythia_def_train\" : 0,\n",
    "            \"pythia_vin_train\" : 0,\n",
    "            \"pythia_dip_train\" : 0,\n",
    "#             \"sherpa_def_train\" : 0\n",
    "            }  \n",
    "    \n",
    "    data_test = {\n",
    "            \"herwig_ang_test\" : 0,\n",
    "            \"pythia_def_test\" : 0,\n",
    "            \"pythia_vin_test\" : 0,\n",
    "            \"pythia_dip_test\" : 0,\n",
    "#             \"sherpa_def_test\" : 0\n",
    "            }  \n",
    "    \n",
    "    data_val = {\n",
    "            \"herwig_ang_val\" : 0,\n",
    "            \"pythia_def_val\" : 0,\n",
    "            \"pythia_vin_val\" : 0,\n",
    "            \"pythia_dip_val\" : 0,\n",
    "#             \"sherpa_def_val\" : 0\n",
    "            }  \n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    [ process[tmp][:ntrain] for j, tmp in enumerate(process) if (j >= i*2 and 2*i+1 >= j) ]\n",
    "    Using this line to combine process_1_H and process_1_QCD. e.g. [herwig_ang_H, herwig_ang_QCD]\n",
    "    \"\"\"\n",
    "    \n",
    "    ntrain = int(length*1)\n",
    "    for i, element in enumerate(data_train):\n",
    "        data_train[element] = pd.concat([ process[tmp][:ntrain] for j, tmp in enumerate(process) if (j >= i*2 and 2*i+1 >= j) ],ignore_index=True,axis=0,join='inner')\n",
    "\n",
    "    ntest = int(length*0.) + ntrain\n",
    "    for i, element in enumerate(data_test):\n",
    "        data_test[element] = pd.concat([ process[tmp][ntrain:ntest] for j, tmp in enumerate(process) if (j >= i*2 and 2*i+1 >= j) ],ignore_index=True,axis=0,join='inner')\n",
    "    \n",
    "    nval = int(length*0.) + ntest\n",
    "    for i, element in enumerate(data_val):\n",
    "        data_val[element] = pd.concat([ process[tmp][ntest:nval] for j, tmp in enumerate(process) if (j >= i*2 and 2*i+1 >= j) ],ignore_index=True,axis=0,join='inner')\n",
    "\n",
    "\n",
    "    print(\"Prepare Target Labels\")\n",
    "    ticks_2 = time.time()\n",
    "    totaltime =  ticks_2 - ticks_1\n",
    "    print(\"\\033[3;33mTime Cost : {:.4f} min\\033[0;m\".format(totaltime/60.))\n",
    "    print(\"\\r\")\n",
    "    \n",
    "    y_train = np.concatenate((np.full(int(length*1), 1), np.full(int(length*1), 0)))\n",
    "    y_test = np.concatenate((np.full(int(length*0.), 1), np.full(int(length*0.), 0)))\n",
    "    y_val = np.concatenate((np.full(int(length*0.), 1), np.full(int(length*0.), 0)))\n",
    "    \n",
    "    \n",
    "    for i, element in enumerate(data_train):\n",
    "        data_train[element][\"target\"] = y_train\n",
    "    \n",
    "    for i, element in enumerate(data_test):\n",
    "        data_test[element][\"target\"] = y_test\n",
    "        \n",
    "    for i, element in enumerate(data_val):\n",
    "        data_val[element][\"target\"] = y_val\n",
    "        \n",
    "        \n",
    "    print(\"Save training, test and validation datasets\")\n",
    "    ticks_2 = time.time()\n",
    "    totaltime =  ticks_2 - ticks_1\n",
    "    print(\"\\033[3;33mTime Cost : {:.4f} min\\033[0;m\".format(totaltime/60.))\n",
    "    print(\"\\r\")\n",
    "    \n",
    "    for i, element in enumerate(data_train):\n",
    "        data_train[element].to_csv(savepath + str(element) + \".csv\",index = 0)\n",
    "        \n",
    "    for i, element in enumerate(data_test):\n",
    "        data_test[element].to_csv(savepath + str(element) + \".csv\",index = 0)\n",
    "        \n",
    "    for i, element in enumerate(data_val):\n",
    "        data_val[element].to_csv(savepath + str(element) + \".csv\",index = 0)\n",
    "\n",
    "    print(\"All Files are saved!\")\n",
    "    ticks_2 = time.time()\n",
    "    totaltime =  ticks_2 - ticks_1\n",
    "    print(\"\\033[3;33mTime Cost : {:.4f} min\\033[0;m\".format(totaltime/60.))\n",
    "    print(\"\\r\")\n",
    "    \n",
    "\n",
    "    print(\"H jet : QCD jet = 1 : 1\")\n",
    "    print(\"\\r\")\n",
    "    print(\"{:^8}{:^15}\".format(\"\",\"Pythia Default\"))\n",
    "    print(\"{:^8}{:^15}\".format(\"Train #\",len(data_train[\"pythia_def_train\"])))\n",
    "    print(\"{:^8}{:^15}\".format(\"Test #\",len(data_test[\"pythia_def_test\"])))\n",
    "    print(\"{:^8}{:^15}\".format(\"Val. #\",len(data_val[\"pythia_def_val\"])))\n",
    "\n",
    "    train = [ len(data_train[element]) for j, element in enumerate(data_train)]\n",
    "    test = [len(data_test[element]) for j, element in enumerate(data_test)]\n",
    "    val = [len(data_val[element]) for j, element in enumerate(data_val)]\n",
    "    \n",
    "    print(\"{:^8}{:^15}{:^15}{:^15}{:^15}\".format(\"\",\"Herwig Angular\",\"Pythia Default\",\"Pythia Vincia\",\"Pythia Dipole\"))\n",
    "    print(\"{:^8}{:^15}{:^15}{:^15}{:^15}\".format(\"Train #\",train[0],train[1],train[2],train[3]))\n",
    "    print(\"{:^8}{:^15}{:^15}{:^15}{:^15}\".format(\"Test #\",test[0],test[1],test[2],test[3]))\n",
    "    print(\"{:^8}{:^15}{:^15}{:^15}{:^15}\".format(\"Val. #\",val[0],val[1],val[2],val[3]))\n",
    "\n",
    "#     print(\"{:^8}{:^15}{:^15}{:^15}\".format(\"\",\"Herwig Angular\",\"Pythia Vincia\",\"Pythia Dipole\"))\n",
    "#     print(\"{:^8}{:^15}{:^15}{:^15}\".format(\"Train #\",train[0],train[1],train[2]))\n",
    "#     print(\"{:^8}{:^15}{:^15}{:^15}\".format(\"Test #\",test[0],test[1],test[2]))\n",
    "#     print(\"{:^8}{:^15}{:^15}{:^15}\".format(\"Val. #\",val[0],val[1],val[2]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Average Value and Variance for Image's Normalization and Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take in a tuple of image lists, calculate average and variance\n",
    "def Get_average_var(image_lists):\n",
    "    tmp_av, tmp_var = np.zeros((3,40,40)), np.zeros((3,40,40))\n",
    "    for i in range(3):\n",
    "        tmp_av[i] = np.average(image_lists[:,i], axis=0)\n",
    "\n",
    "        tmp_var[i] = np.var(image_lists[:,i], axis=0)\n",
    "\n",
    "    return tmp_av, tmp_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 256/792 [21:19<42:08,  4.72s/it]  "
     ]
    }
   ],
   "source": [
    "HOMEPATH = \"/dicos_ui_home/alanchung/Universality_Boosetd_Higgs/\"\n",
    "JetImagePath =  HOMEPATH + \"Data_ML/\" +\"Image_Directory/\"\n",
    "savepath = HOMEPATH + \"Data_ML/\"\n",
    "\n",
    "process = {\n",
    "            \"herwig_ang_H\" : 0,\n",
    "            \"herwig_ang_QCD\" : 0,\n",
    "            \"pythia_def_H\" : 0,\n",
    "            \"pythia_def_QCD\" : 0,\n",
    "                \"pythia_vin_H\" : 0,\n",
    "                \"pythia_vin_QCD\" : 0,\n",
    "                \"pythia_dip_H\" : 0,\n",
    "                \"pythia_dip_QCD\" : 0 ,\n",
    "#                 \"sherpa_def_H\" : 0,\n",
    "#                 \"sherpa_def_QCD\" : 0\n",
    "              }  \n",
    "    \n",
    "for i, element in enumerate(process):\n",
    "    process[element] = pd.read_csv(savepath + str(element) + \"_dict.csv\")\n",
    "\n",
    "\n",
    "    \n",
    "try:\n",
    "    \n",
    "    for i, element in enumerate(process):\n",
    "        av = np.load(savepath + \"average\" + \"_\" + str(element) + \".npy\")\n",
    "        var = np.load(savepath + \"variance\" + \"_\" + str(element) + \".npy\")\n",
    "        print(str(element)+\" average shape: \",av.shape)\n",
    "        print(str(element)+\" varianve shape: \",var.shape)\n",
    "    \n",
    "except:\n",
    "\n",
    "    batch_size = 1000\n",
    "\n",
    "    nan_path_list = []\n",
    "    \n",
    "    for i in range(len(process)):\n",
    "        nan_path_list.append([])\n",
    "\n",
    "    for i, element in enumerate(process):\n",
    "        av, var = np.zeros((3,40,40)), np.zeros((3,40,40))\n",
    "        length = 0\n",
    "        nb_samples = len(process[element])\n",
    "        for start in tqdm(range(0, nb_samples, batch_size)):\n",
    "\n",
    "            x_batch = []\n",
    "            end = min(start + batch_size, nb_samples)\n",
    "\n",
    "            for img_path in range(start, end):\n",
    "\n",
    "                x_jet_path = JetImagePath + process[element][\"JetImage\"].iloc[img_path]\n",
    "                x_jet = np.load(x_jet_path)[\"jet_image\"]\n",
    "\n",
    "                if np.isnan(x_jet).any() == True:\n",
    "    #             if np.nansum(x_train_jet) == 0:\n",
    "                    nan_path_list[i].append(x_jet_path)\n",
    "                    continue \n",
    "                x_batch.append(x_jet)\n",
    "\n",
    "            x_batch = np.array(x_batch)\n",
    "\n",
    "            tmp_av, tmp_var = Get_average_var(x_batch)\n",
    "            av += tmp_av*len(x_batch)\n",
    "            var += tmp_var\n",
    "            length += len(x_batch)\n",
    "\n",
    "\n",
    "    #         if start == 3000:\n",
    "    #             break\n",
    "\n",
    "\n",
    "        av = av/length\n",
    "        np.save(savepath + \"average\" + \"_\" + str(element) + \".npy\", av)\n",
    "        np.save(savepath + \"variance\" + \"_\" + str(element) + \".npy\", var)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
