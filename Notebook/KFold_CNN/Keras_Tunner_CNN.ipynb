{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "perceived-magic",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Tensorflow Version is 2.4.1\n",
      "INFO:root:Keras Version is 2.4.0\n",
      "INFO:root:[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7824930124829175963\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10485760000\n",
      "locality {\n",
      "  bus_id: 2\n",
      "  numa_node: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 49387416044665903\n",
      "physical_device_desc: \"device: 0, name: A100-SXM-80GB, pci bus id: 0000:48:00.0, compute capability: 8.0\"\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n",
      "Sun Dec 12 08:27:54 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.73.01    Driver Version: 460.73.01    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  A100-SXM-80GB       On   | 00000000:48:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    94W / 400W |  43061MiB / 81251MiB |     97%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# encoding: utf-8\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "# Install TensorFlow\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten , Convolution2D, MaxPooling2D , Lambda, Conv2D, Activation,Concatenate\n",
    "from tensorflow.keras.layers import ActivityRegularization\n",
    "from tensorflow.keras.optimizers import Adam , SGD , Adagrad\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import regularizers , initializers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import NumpyArrayIterator\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "# from xgboost import XGBClassifier\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn import metrics\n",
    "\n",
    "# !pip3 install keras-tuner --upgrade\n",
    "# !pip3 install autokeras\n",
    "import kerastuner as kt\n",
    "import autokeras as ak\n",
    "\n",
    "# Import local libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "import importlib\n",
    "from tqdm import tqdm \n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "importlib.reload(logging)\n",
    "logging.basicConfig(level = logging.INFO)\n",
    "\n",
    "os.environ['NUMEXPR_MAX_THREADS'] = '64'\n",
    "os.environ['NUMEXPR_NUM_THREADS'] = '64'\n",
    "\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#   # Restrict TensorFlow to only use the first GPU\n",
    "try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "    gpus[0],\n",
    "    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=10000)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "except RuntimeError as e:\n",
    "# Visible devices must be set before GPUs have been initialized\n",
    "    logging.info(e)\n",
    "\n",
    "\n",
    "\n",
    "logging.info(\"Tensorflow Version is {}\".format(tf.__version__))\n",
    "logging.info(\"Keras Version is {}\".format(tf.keras.__version__))\n",
    "from tensorflow.python.client import device_lib\n",
    "logging.info(device_lib.list_local_devices())\n",
    "tf.device('/device:XLA_GPU:0')\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sixth-guess",
   "metadata": {},
   "source": [
    "Ref: https://keras.io/keras_tuner/#quick-introduction  \n",
    "Ref: https://keras.io/guides/keras_tuner/getting_started/   \n",
    "Ref: https://keras.io/api/keras_tuner/tuners/base_tuner/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "optional-scout",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Loading_Data(data_source, datadict, start=0, stop=20000):\n",
    "    x_jet, target = [], []\n",
    "\n",
    "    time.sleep(0.5)\n",
    "    for k in tqdm(range(start,len(data_source))):\n",
    "        x_jet_path = savepath + \"Image_Directory/\"+ data_source[\"JetImage\"].iloc[k]\n",
    "        x_jet_tmp = np.load(x_jet_path)[\"jet_image\"]\n",
    "        if np.isnan(x_jet_tmp).any() == True:\n",
    "            continue \n",
    "\n",
    "        target.append(data_source[\"Y\"].iloc[k])\n",
    "        x_jet_tmp = np.divide((x_jet_tmp - Norm_dict[datadict][0]), (np.sqrt(Norm_dict[datadict][1])+1e-5))#[0].reshape(1,40,40)\n",
    "        x_jet.append(x_jet_tmp)\n",
    "\n",
    "\n",
    "        if k == stop:\n",
    "            break\n",
    "\n",
    "    return np.asarray(x_jet), np.asarray(target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "subsequent-plain",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:All Files are loaded!\n",
      "INFO:root:H jet : QCD jet = 1 : 1\n",
      "INFO:root:\n",
      "INFO:root:        pythia_def_train\n",
      "INFO:root:Train #     307456     \n",
      "INFO:root:total_list Index(['JetImage', 'Y'], dtype='object')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.77 s, sys: 309 ms, total: 3.08 s\n",
      "Wall time: 3.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "HOMEPATH = \"/dicos_ui_home/alanchung/Universality_Boosetd_Higgs/\"\n",
    "JetImagePath =  HOMEPATH + \"Data_ML/\" +\"Image_Directory/\"\n",
    "savepath = HOMEPATH + \"Data_ML/\"\n",
    "\n",
    "\n",
    "    \n",
    "try:\n",
    "    \n",
    "    data_dict ={\n",
    "#             \"herwig_ang\" : [0,0],\n",
    "            \"pythia_def\" : [0,0],\n",
    "#             \"pythia_vin\" : [0,0],\n",
    "#             \"pythia_dip\" : [0,0],\n",
    "#             \"sherpa_def\" : [0,0],\n",
    "              }  \n",
    "    \n",
    "    Norm_dict ={\n",
    "#             \"herwig_ang\" : [0,0],\n",
    "            \"pythia_def\" : [0,0],\n",
    "#             \"pythia_vin\" : [0,0],\n",
    "#             \"pythia_dip\" : [0,0],\n",
    "#             \"sherpa_def\" : [0,0],\n",
    "              }  \n",
    "    \n",
    "    data_train = {\n",
    "#             \"herwig_ang_train\" : 0,\n",
    "            \"pythia_def_train\" : 0,\n",
    "#             \"pythia_vin_train\" : 0,\n",
    "#             \"pythia_dip_train\" : 0,\n",
    "#             \"sherpa_def_train\" : 0\n",
    "            }  \n",
    "    \n",
    "\n",
    "    for i, element in enumerate(data_dict):\n",
    "        data_dict[element][0] = pd.read_csv(savepath + str(element) + \"_H_dict.csv\")\n",
    "        data_dict[element][1] = pd.read_csv(savepath + str(element) + \"_QCD_dict.csv\")\n",
    "#         logging.info(len(data_dict[element][0]),len(data_dict[element][1]))\n",
    "    \n",
    "    for i, element in enumerate(Norm_dict):\n",
    "        average_H = np.load(savepath + \"average\" + \"_\" + str(element) + \"_H.npy\")\n",
    "        variance_H = np.load(savepath + \"variance\" + \"_\" + str(element) + \"_H.npy\")\n",
    "        average_QCD = np.load(savepath + \"average\" + \"_\" + str(element) + \"_QCD.npy\")\n",
    "        variance_QCD = np.load(savepath + \"variance\" + \"_\" + str(element) + \"_QCD.npy\")\n",
    "        length_H = len(data_dict[element][0])\n",
    "        length_QCD = len(data_dict[element][1])\n",
    "        \n",
    "        Norm_dict[element][0] = (average_H*length_H + average_QCD*length_QCD)/(length_H+length_QCD)\n",
    "        Norm_dict[element][1] =  variance_H + variance_QCD\n",
    "        \n",
    "    for i,(element, dict_element) in enumerate(zip(data_train, data_dict)):\n",
    "        \n",
    "        \"\"\"\n",
    "        Pt Range Study\n",
    "        \"\"\"\n",
    "        pt_min, pt_max = 300, 500\n",
    "        tmp = pd.read_csv(HOMEPATH + \"Notebook/KFold_CNN/\" + str(element) + \".csv\")\n",
    "        tmp = tmp[(tmp[\"PTJ_0\"] >= pt_min)  & (tmp[\"PTJ_0\"] < pt_max)]\n",
    "        tmp = tmp[(tmp[\"MJ_0\"] >= 110)  & (tmp[\"MJ_0\"] < 160)]\n",
    "        data_train[element] = shuffle(tmp)\n",
    "        \n",
    "        H_tmp = data_train[element][data_train[element][\"target\"] == 1]\n",
    "        QCD_tmp = data_train[element][data_train[element][\"target\"] == 0]\n",
    "        \n",
    "        H_dict = data_dict[dict_element][0].iloc[H_tmp[\"index\"].values]\n",
    "        QCD_dict = data_dict[dict_element][1].iloc[QCD_tmp[\"index\"].values]\n",
    "        \n",
    "        data_train[element] = pd.concat([H_dict, QCD_dict], ignore_index=True, axis=0,join='inner')\n",
    "        data_train[element] = shuffle(data_train[element])\n",
    "        \n",
    "\n",
    "\n",
    "    logging.info(\"All Files are loaded!\")\n",
    "\n",
    "    logging.info(\"H jet : QCD jet = 1 : 1\")\n",
    "    logging.info(\"\\r\")\n",
    "    train = [ len(data_train[element]) for j, element in enumerate(data_train)]\n",
    "    logging.info(\"{:^8}{:^15}\".format(\"\",str(element)))\n",
    "    logging.info(\"{:^8}{:^15}\".format(\"Train #\",train[0]))\n",
    "    \n",
    "    \n",
    "    for i, element in enumerate(data_train):\n",
    "        total_list = data_train[element].columns\n",
    "        break\n",
    "    \n",
    "    logging.info(\"total_list {}\".format(total_list))\n",
    "\n",
    "except:\n",
    "    \n",
    "    logging.info(\"Please create training, test and validation datasets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "baking-upgrade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 50000/307456 [05:33<28:38, 149.83it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.9 s, sys: 6.53 s, total: 39.4 s\n",
      "Wall time: 5min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# x_jet, target = Loading_Data(data_train[\"pythia_def_train\"], \"pythia_def\", start=0, stop= len(data_train[\"pythia_def_train\"]))\n",
    "x_jet, target = Loading_Data(data_train[\"pythia_def_train\"], \"pythia_def\", start=0, stop= 50000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "advance-oxide",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:training length: 40000\n",
      "INFO:root:validation length: 5000\n",
      "INFO:root:test length: 5001\n",
      "INFO:root:Total length: 50001\n",
      "INFO:root:Total length: 50001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.73 ms, sys: 2.63 ms, total: 4.36 ms\n",
      "Wall time: 3.31 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "length = len(x_jet)\n",
    "x_train_jet, target_train = x_jet[:int(length/10*8)], target[:int(length/10*8)]\n",
    "x_val_jet, target_val = x_jet[int(length/10*8):int(length/10*9)], target[int(length/10*8):int(length/10*9)]\n",
    "x_test_jet, target_test = x_jet[int(length/10*9):], target[int(length/10*9):]\n",
    "\n",
    "logging.info(\"training length: {}\".format(len(x_train_jet)))\n",
    "logging.info(\"validation length: {}\".format(len(x_val_jet)))\n",
    "logging.info(\"test length: {}\".format(len(x_test_jet)))\n",
    "logging.info(\"Total length: {}\".format(len(x_train_jet)+len(x_val_jet)+len(x_test_jet)))\n",
    "logging.info(\"Total length: {}\".format(length))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "military-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define Function\n",
    "\"\"\"\n",
    "\n",
    "def CNN_Model(hp):\n",
    "    \"\"\"\n",
    "    Declare the Input Shape\n",
    "    \"\"\"\n",
    "    input_shape = (3,40,40)#(1, 40,40)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Create a Sequential Model\n",
    "    \"\"\"\n",
    "    model_CNN = Sequential(name = \"Model_CNN_Pythia_Default\")\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Add a \"Conv2D\" Layer into the Sequential Model\n",
    "    \"\"\"\n",
    "    model_CNN.add(Conv2D(\n",
    "                     filters=hp.Int(\"Conv2D_1_filter\", min_value=16, max_value=128, step=16), \n",
    "                     kernel_size=hp.Choice('Conv2D_1_kernel', values = [3,5,7]),\n",
    "                     strides=hp.Choice('Conv2D_1_stride', values = [1]),\n",
    "                     activation='relu',\n",
    "                     data_format='channels_first',\n",
    "    #                data_format='channels_last',\n",
    "                    input_shape=input_shape, \n",
    "                    name = 'Conv2D_1'))\n",
    "\n",
    "    \"\"\"\n",
    "    Add a \"MaxPooling2D\" Layer into the Sequential Model\n",
    "    \"\"\"\n",
    "    model_CNN.add(MaxPooling2D(pool_size=(2, 2), \n",
    "                               strides=(2, 2),\n",
    "#                                data_format='channels_first', \n",
    "    #                            data_format='channels_last',\n",
    "                               name = 'jet_MaxPooling_1'))\n",
    "\n",
    "    \"\"\"\n",
    "    Add a \"Conv2D\" Layer into the Sequential Model\n",
    "    \"\"\"\n",
    "    model_CNN.add(Conv2D(\n",
    "                 filters=hp.Int(\"Conv2D_2_filter\", min_value=16, max_value=128, step=16), \n",
    "                 kernel_size=hp.Choice('Conv2D_2_kernel', values = [3,5,7]),\n",
    "                 strides=hp.Choice('Conv2D_2_stride', values = [1]),\n",
    "                 activation='relu',\n",
    "                 data_format='channels_first',\n",
    "#                data_format='channels_last',\n",
    "                input_shape=input_shape, \n",
    "                name = 'Conv2D_2'))\n",
    "\n",
    "    \"\"\"\n",
    "    Add a \"MaxPooling2D\" Layer into the Sequential Model\n",
    "    \"\"\"\n",
    "    model_CNN.add(MaxPooling2D(pool_size=(2, 2), \n",
    "                               strides=(2, 2),\n",
    "                               data_format='channels_first', \n",
    "    #                            data_format='channels_last',\n",
    "                               name = 'jet_MaxPooling_2'))\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Flatten\n",
    "    \"\"\"\n",
    "    model_CNN.add(Flatten(name = 'jet_flatten'))\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Put Output from Flatten Layer into \"Dense\" Layer with 300 neurons\n",
    "    \"\"\"\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 3)):\n",
    "        model_CNN.add(\n",
    "            keras.layers.Dense(\n",
    "                # Tune number of units separately.\n",
    "                units=hp.Int(f\"units_{i}\", min_value=100, max_value=500, step=50),\n",
    "                activation='relu',\n",
    "            )\n",
    "        )\n",
    "\n",
    "    \n",
    "    if hp.Boolean(\"dropout\"):\n",
    "        model_CNN.add(keras.layers.Dropout(rate=0.01, name = 'Dropout'))\n",
    "\n",
    "    \"\"\"\n",
    "    Add Output \"Dense\" Layer with 2 neurons into the Sequential Model\n",
    "    \"\"\"\n",
    "    model_CNN.add(Dense(1, activation='sigmoid', name = 'output'))\n",
    "    # model_CNN.add(Dense(2, activation='softmax', name = 'output'))\n",
    "\n",
    "    \"\"\"\n",
    "    Declare the Optimizer\n",
    "    \"\"\"\n",
    "    learning_rate = hp.Float(\"lr\", min_value=1e-5, max_value=1e-2, sampling=\"log\")\n",
    "    model_opt = keras.optimizers.Adadelta(learning_rate=learning_rate)\n",
    "    # model_opt = keras.optimizers.Adam()\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Compile Model\n",
    "    \"\"\"\n",
    "    model_CNN.compile(\n",
    "    #                     loss=\"categorical_crossentropy\",\n",
    "                       loss = \"binary_crossentropy\",\n",
    "                       optimizer=model_opt,\n",
    "                       metrics=[\"accuracy\",\"mse\"])\n",
    "\n",
    "    \"\"\"\n",
    "    Print Architecture\n",
    "    \"\"\"\n",
    "    model_CNN.summary()\n",
    "\n",
    "    return model_CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "violent-payday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model_CNN_Pythia_Default\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv2D_1 (Conv2D)            (None, 16, 38, 38)        448       \n",
      "_________________________________________________________________\n",
      "jet_MaxPooling_1 (MaxPooling (None, 8, 19, 38)         0         \n",
      "_________________________________________________________________\n",
      "Conv2D_2 (Conv2D)            (None, 16, 17, 36)        1168      \n",
      "_________________________________________________________________\n",
      "jet_MaxPooling_2 (MaxPooling (None, 16, 8, 18)         0         \n",
      "_________________________________________________________________\n",
      "jet_flatten (Flatten)        (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               230500    \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 232,217\n",
      "Trainable params: 232,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Search space summary\n",
      "Default search space size: 10\n",
      "Conv2D_1_filter (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 128, 'step': 16, 'sampling': None}\n",
      "Conv2D_1_kernel (Choice)\n",
      "{'default': 3, 'conditions': [], 'values': [3, 5, 7], 'ordered': True}\n",
      "Conv2D_1_stride (Choice)\n",
      "{'default': 1, 'conditions': [], 'values': [1], 'ordered': True}\n",
      "Conv2D_2_filter (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 128, 'step': 16, 'sampling': None}\n",
      "Conv2D_2_kernel (Choice)\n",
      "{'default': 3, 'conditions': [], 'values': [3, 5, 7], 'ordered': True}\n",
      "Conv2D_2_stride (Choice)\n",
      "{'default': 1, 'conditions': [], 'values': [1], 'ordered': True}\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 3, 'step': 1, 'sampling': None}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 100, 'max_value': 500, 'step': 50, 'sampling': None}\n",
      "dropout (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "lr (Float)\n",
      "{'default': 1e-05, 'conditions': [], 'min_value': 1e-05, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n",
      "CPU times: user 137 ms, sys: 8.69 ms, total: 146 ms\n",
      "Wall time: 156 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tuner = kt.RandomSearch(hypermodel=CNN_Model,\n",
    "                        objective=\"val_loss\",\n",
    "                        max_trials=3,\n",
    "                        executions_per_trial=2, #The number of models that should be built and fit for each trial\n",
    "                        overwrite=True,\n",
    "                        directory=\"CNN_Model_Hyper_Tunning\",\n",
    "                        project_name=\"Universality\"\n",
    "                        )\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bibliographic-liberal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 00m 45s]\n",
      "val_loss: 0.6931541264057159\n",
      "\n",
      "Best val_loss So Far: 0.6799198985099792\n",
      "Total elapsed time: 00h 02m 20s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(np.asarray(x_train_jet), np.asarray(target_train),\n",
    "             epochs=5, \n",
    "             validation_data=(np.asarray(x_val_jet), np.asarray(target_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "damaged-korean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in CNN_Model_Hyper_Tunning/Universality\n",
      "Showing 10 best trials\n",
      "Objective(name='val_loss', direction='min')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "Conv2D_1_filter: 48\n",
      "Conv2D_1_kernel: 7\n",
      "Conv2D_1_stride: 1\n",
      "Conv2D_2_filter: 96\n",
      "Conv2D_2_kernel: 7\n",
      "Conv2D_2_stride: 1\n",
      "num_layers: 1\n",
      "units_0: 400\n",
      "dropout: False\n",
      "lr: 0.001576691183648427\n",
      "units_1: 250\n",
      "Score: 0.6799198985099792\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "Conv2D_1_filter: 128\n",
      "Conv2D_1_kernel: 7\n",
      "Conv2D_1_stride: 1\n",
      "Conv2D_2_filter: 32\n",
      "Conv2D_2_kernel: 3\n",
      "Conv2D_2_stride: 1\n",
      "num_layers: 2\n",
      "units_0: 350\n",
      "dropout: True\n",
      "lr: 0.0015407870950216247\n",
      "units_1: 100\n",
      "Score: 0.68257936835289\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "Conv2D_1_filter: 64\n",
      "Conv2D_1_kernel: 7\n",
      "Conv2D_1_stride: 1\n",
      "Conv2D_2_filter: 32\n",
      "Conv2D_2_kernel: 5\n",
      "Conv2D_2_stride: 1\n",
      "num_layers: 1\n",
      "units_0: 200\n",
      "dropout: True\n",
      "lr: 2.3386744927248327e-05\n",
      "units_1: 100\n",
      "Score: 0.6931541264057159\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "charitable-triumph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model_CNN_Pythia_Default\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv2D_1 (Conv2D)            (None, 48, 34, 34)        7104      \n",
      "_________________________________________________________________\n",
      "jet_MaxPooling_1 (MaxPooling (None, 24, 17, 34)        0         \n",
      "_________________________________________________________________\n",
      "Conv2D_2 (Conv2D)            (None, 96, 11, 28)        112992    \n",
      "_________________________________________________________________\n",
      "jet_MaxPooling_2 (MaxPooling (None, 96, 5, 14)         0         \n",
      "_________________________________________________________________\n",
      "jet_flatten (Flatten)        (None, 6720)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 400)               2688400   \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 401       \n",
      "=================================================================\n",
      "Total params: 2,808,897\n",
      "Trainable params: 2,808,897\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"Model_CNN_Pythia_Default\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv2D_1 (Conv2D)            (None, 128, 34, 34)       18944     \n",
      "_________________________________________________________________\n",
      "jet_MaxPooling_1 (MaxPooling (None, 64, 17, 34)        0         \n",
      "_________________________________________________________________\n",
      "Conv2D_2 (Conv2D)            (None, 32, 15, 32)        18464     \n",
      "_________________________________________________________________\n",
      "jet_MaxPooling_2 (MaxPooling (None, 32, 7, 16)         0         \n",
      "_________________________________________________________________\n",
      "jet_flatten (Flatten)        (None, 3584)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 350)               1254750   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               35100     \n",
      "_________________________________________________________________\n",
      "Dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,327,359\n",
      "Trainable params: 1,327,359\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"Model_CNN_Pythia_Default\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv2D_1 (Conv2D)            (None, 64, 34, 34)        9472      \n",
      "_________________________________________________________________\n",
      "jet_MaxPooling_1 (MaxPooling (None, 32, 17, 34)        0         \n",
      "_________________________________________________________________\n",
      "Conv2D_2 (Conv2D)            (None, 32, 13, 30)        25632     \n",
      "_________________________________________________________________\n",
      "jet_MaxPooling_2 (MaxPooling (None, 32, 6, 15)         0         \n",
      "_________________________________________________________________\n",
      "jet_flatten (Flatten)        (None, 2880)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 200)               576200    \n",
      "_________________________________________________________________\n",
      "Dropout (Dropout)            (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 611,505\n",
      "Trainable params: 611,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.rho\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.rho\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.rho\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "best_model = tuner.get_best_models(num_models=3)[0]\n",
    "# len(best_model)\n",
    "# best_model[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "crucial-recruitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test =  best_model.predict(np.asarray(x_test_jet))\n",
    "discriminator_test = prediction_test\n",
    "discriminator_test = discriminator_test/(max(discriminator_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "laughing-bulgaria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>max_sig</th>\n",
       "      <th>r05</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.815317</td>\n",
       "      <td>1.567296</td>\n",
       "      <td>8.88968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AUC   max_sig      r05\n",
       "0  0.815317  1.567296  8.88968"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Performance_Frame = {\n",
    "                \"AUC\" : [0],\n",
    "                \"max_sig\" : [0],\n",
    "                \"r05\" : [0],\n",
    "                }\n",
    "Performance_Frame[\"AUC\"][0] = metrics.roc_auc_score(target_test,discriminator_test)\n",
    "FalsePositiveFull, TruePositiveFull, _ = metrics.roc_curve(target_test,discriminator_test)\n",
    "tmp = np.where(FalsePositiveFull != 0)\n",
    "Performance_Frame[\"max_sig\"][0] = max(TruePositiveFull[tmp]/np.sqrt(FalsePositiveFull[tmp])) \n",
    "tmp = np.where(TruePositiveFull >= 0.5)\n",
    "Performance_Frame[\"r05\"][0]= 1./FalsePositiveFull[tmp[0][0]]\n",
    "\n",
    "\n",
    "dataframe = pd.DataFrame(Performance_Frame)\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "normal-determination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model_CNN_Pythia_Default\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv2D_1 (Conv2D)            (None, 48, 34, 34)        7104      \n",
      "_________________________________________________________________\n",
      "jet_MaxPooling_1 (MaxPooling (None, 24, 17, 34)        0         \n",
      "_________________________________________________________________\n",
      "Conv2D_2 (Conv2D)            (None, 96, 11, 28)        112992    \n",
      "_________________________________________________________________\n",
      "jet_MaxPooling_2 (MaxPooling (None, 96, 5, 14)         0         \n",
      "_________________________________________________________________\n",
      "jet_flatten (Flatten)        (None, 6720)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 400)               2688400   \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 401       \n",
      "=================================================================\n",
      "Total params: 2,808,897\n",
      "Trainable params: 2,808,897\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.save(\"./Tuning.h5\")\n",
    "model = load_model(\"./Tuning.h5\", compile =False)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "christian-slovak",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>max_sig</th>\n",
       "      <th>r05</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.815317</td>\n",
       "      <td>1.567296</td>\n",
       "      <td>8.88968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AUC   max_sig      r05\n",
       "0  0.815317  1.567296  8.88968"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_test =  model.predict(np.asarray(x_test_jet))\n",
    "discriminator_test = prediction_test\n",
    "discriminator_test = discriminator_test/(max(discriminator_test))\n",
    "Performance_Frame = {\n",
    "                \"AUC\" : [0],\n",
    "                \"max_sig\" : [0],\n",
    "                \"r05\" : [0],\n",
    "                }\n",
    "Performance_Frame[\"AUC\"][0] = metrics.roc_auc_score(target_test,discriminator_test)\n",
    "FalsePositiveFull, TruePositiveFull, _ = metrics.roc_curve(target_test,discriminator_test)\n",
    "tmp = np.where(FalsePositiveFull != 0)\n",
    "Performance_Frame[\"max_sig\"][0] = max(TruePositiveFull[tmp]/np.sqrt(FalsePositiveFull[tmp])) \n",
    "tmp = np.where(TruePositiveFull >= 0.5)\n",
    "Performance_Frame[\"r05\"][0]= 1./FalsePositiveFull[tmp[0][0]]\n",
    "\n",
    "\n",
    "dataframe = pd.DataFrame(Performance_Frame)\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-essay",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
